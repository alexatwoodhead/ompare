<?xml version="1.0" encoding="UTF-8"?>
<Export generator="IRIS" version="26">
<Class name="ompare.Schedule">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>]]></Description>
<Super>%SYS.Task.Definition</Super>
<TimeCreated>64118,65813.451823</TimeCreated>

<Property name="Environment">
<Description>
Logical development pipeline environment eg: "BASE","TEST","UAT","LIVE"
For example development is implemented in "BASE", deployed to "TEST" for user testing,
the patch is validated in "UAT", before being published to "LIVE"
Environment may also include platform versioning for example as a migration
project from Cache2010_BASE to IRIS2019_BASE</Description>
<Type>%String</Type>
<Required>1</Required>
<Parameter name="MINLEN" value="1"/>
</Property>

<Property name="Namespaces">
<Description>
Comma seperated list of Available Namespaces to execute runners within
Supports trailing wild-cards for example INST-* will match "INST-MARS" and "INST-LUNAR"
"*" on its own would match ALL namesapces
Supports leading "-" (minus character) to exclude items in list
For example: *,-INST-LUNAR
eg: "USER,OBSERVER,INTEG-MARS,INTEG-LUNAR,INST-MARS"</Description>
<Type>%String</Type>
<Required>1</Required>
<Parameter name="MAXLEN" value="1500"/>
<Parameter name="MINLEN" value="3"/>
</Property>

<Property name="RunSourceHandlers">
<Description>
When the schedule runs should is profile the selected namespaces for Classes, Routines, Ensemble Lookup Tables, etc
to generate "Signature" / "Fingerprint" of content</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ExportToFile">
<Description>
When the schedule runs should the current "Signatures" for content be exported to the filesystem</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ExportDirectory">
<Description>
The directory where files for "Signatures" and "Source" are exported to</Description>
<Type>%String</Type>
<Parameter name="MAXLEN" value="220"/>
</Property>

<Property name="ExportCompression">
<Type>%Boolean</Type>
<InitialExpression>1</InitialExpression>
</Property>

<Property name="OverwriteSourceOnReLoad">
<Description>
In completed development a signature should match content it is generated from
However when developing new or extending existing SourceHandlers 
inconsistent Source can get introduced to reporting server
This flag allows Source for a signature to be "corrected"
as SourceHandler implementation is itterated and tested on the reporting server.</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
</Property>

<Method name="ExportDirectorySet">
<Description>
Correct the Path set via Task Schedule Web Page</Description>
<FormalSpec>val</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if val="" set i%ImportDirectory=val Quit $$$OK
	if $zcvt($SYSTEM.Version.GetOS(),"U")="UNIX" {
		if $E(val,*)'="/" {
			// Unix / Linux without trailing directory character
			set val=val_"/"
		}
	} elseif $E(val,*)'="\" {
		// Assume windows without trailing directory character
		set val=val_"\"
	}
	set i%ExportDirectory=val
	Q $$$OK
]]></Implementation>
</Method>

<Property name="BackupSourceCode">
<Description>
Flag to indicate whether a standard export of source code should be taken from each namespace of interest </Description>
<Type>%Boolean</Type>
</Property>

<Property name="ImportFromFile">
<Description>
When the schedule runs should signatures and source be imported (from remote systems).</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ImportDirectory">
<Description>
The directory where files for "Signatures" and "Source" are imported from</Description>
<Type>%String</Type>
<Parameter name="MAXLEN" value="220"/>
</Property>

<Property name="DiscardProfileData">
<Description>
For a non-reporting instance
Clear SourceCode profile signatures and data prior to running the schedule
Clear SourceCode profile signatures and data prior to running the schedule
ie: After export files for signatures and source code has been written
Caution - When Enabled on a Reporting Server this will
Also clear Signature data collected from other systems</Description>
<Type>%Boolean</Type>
</Property>

<Method name="ImportDirectorySet">
<Description>
Correct the Path set via Task Schedule Web Page</Description>
<FormalSpec>val</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if val="" set i%ImportDirectory=val Quit $$$OK
	if $zcvt($SYSTEM.Version.GetOS(),"U")="UNIX" {
		if $E(val,*)'="/" {
			// Unix / Linux without trailing directory character
			set val=val_"/"
		}
	} elseif $E(val,*)'="\" {
		// Assume windows without trailing directory character
		set val=val_"\"
	}
	set i%ImportDirectory=val
	Q $$$OK
]]></Implementation>
</Method>

<Property name="ReImportUpdatedFiles">
<Description>
Flag to control whether files that have been imported previously should be reprocessed IF the filesystem timestamp has a newer modified datetime.</Description>
<Type>%Boolean</Type>
</Property>

<Property name="DeleteImportedFiles">
<Description>
Flag to control whether files that have been processed for import should be deleted from the Import Directory</Description>
<Type>%Boolean</Type>
</Property>

<Property name="RetainExportDays">
<Description>
Number of days to retain files containing "Signatures" and "Source" that have been exported to the Export Directory</Description>
<Type>%Integer</Type>
</Property>

<Property name="RetainSigSrcHistoricVersions">
<Description><![CDATA[
Number of historic versions to retain of global data for Signatures and Source snapshots
Set to "0" if we do not wish to hold historic data in globals for this system.<br/>
Set to "-1" to prevent analysis to discard obsolete source code entries. Useful for ECP mapped systems.]]></Description>
<Type>%Integer</Type>
</Property>

<Property name="EnableLogging">
<Description>
Switch to control whether SourceHandlers provide verbose logging during analysis of namespaces
Where a source handler generates "Signatures" and "Source" snapshots.</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
<Required>1</Required>
</Property>

<Property name="IncludeSourceCode">
<Description>
Switch used by SourceHandlers to control whether to include Source Information. ie: Data that can be exported into "Source" Files</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
<Required>1</Required>
</Property>

<Property name="Debug">
<Description>
Use by Schedule for verbose logging during Task Processing
A Cache schedule can be configured to send output to a file</Description>
<Type>%Boolean</Type>
</Property>

<Parameter name="ExportSignaturePrefix">
<Description>
The file prefix use for Exporting "Signature" files
The file prefix used to identify Import "Signature" files for processing</Description>
<Default>SrcUtilDataSig</Default>
</Parameter>

<Parameter name="ExportSourcePrefix">
<Description>
The file prefix use for Exporting "Source" files
The file prefix used to identify Import "Source" files for processing </Description>
<Default>SrcUtilDataSrc</Default>
</Parameter>

<Property name="STDOUT">
<Description>
Device to send debugging information to</Description>
<Type>%String</Type>
<Internal>1</Internal>
<Private>1</Private>
</Property>

<Property name="PerNamespaceSourceHandlers">
<Description>
Enforced list SourceHandlers to run in each namespace
If set this list is used instead of searching for subclasses of SourceHandler Base
Useful for Mirrored environments when run on Backup Mirror</Description>
<Type>%String</Type>
<MultiDimensional>1</MultiDimensional>
</Property>

<Property name="SystemSourceHandlers">
<Description>
Enforced list SourceHandlers to run once
If set this list is used instead of searching for subclasses of SourceHandler Base
Useful for Mirrored environments when run on Backup Mirror</Description>
<Type>%String</Type>
<MultiDimensional>1</MultiDimensional>
</Property>

<Property name="SrcVersionTokenStart">
<Description>
Source control systems may update a token in source code
with the brahc and version of code being checked-in
To filter out this sequence set the token start sequence used  </Description>
<Type>%String</Type>
<InitialExpression>"$I"_"d"</InitialExpression>
</Property>

<Property name="SrcVersionTokenEnd">
<Description>
As with property SrcVersionTokenStart, to filter out version string added to code
by source control system set the token end sequence</Description>
<Type>%String</Type>
<InitialExpression>"$"</InitialExpression>
</Property>

<Property name="SrcVersionParameter">
<Type>%String</Type>
<InitialExpression>"SrcVer"</InitialExpression>
</Property>

<Parameter name="ExportItemTypes">
<Description>
Used by GenerateBackupSourceCode</Description>
<Default>*.CLS,*.MAC,*.INC,*.RUL,*.HL7,*.AST</Default>
</Parameter>

<Method name="OnTask">
<Description><![CDATA[
Entry method called by IRIS TaskScheduler for processing.<br/>
<h3>Profiling Source code</h3>
<p>Searches for Classes that implement ompare.SourceHandler.Base.
For each namespace configured on the Schedule, run each SourceHandler.
Each source handler is responsible for building and storing signatures and optionally an extract of source code (eg: Content of a method)
</p>
<p>
<h3>Exporting Signatures</h3>
Builds a Signature file in the Export Directory that can be imported into other systems for reporting.</br>
Builds a Source file in the Export Directory that can be imported into other systems for Source Comparison details.</br>
Exported files are gzip compressed for efficent transfer between systems.</br>
Export Signature files have the filename convention
<example>
[ExportSignaturePrefix] + [Environment] + [CCYYMMDDHHMM] + ".gz"

SrcUtilDataSigTESTX201608011247.gz

Where:
  ExportSignaturePrefix = "SrcUtilDataSig"
  Environment = "TESTX"
  CCYYMMDDHHMM = 2016-08-01 12:47
</example>
Export Source files have the filename convention
<example>
[ExportSourcePrefix] + [Environment] + [CCYYMMDDHHMM] + ".gz"

SrcUtilDataSrcTESTX201607291247.gz

Where:
  ExportSignaturePrefix = "SrcUtilDataSrc"
  Environment = "TESTX"
  CCYYMMDDHHMM = 2016-07-29 12:47
</example>
</p>
<h3>Purge Exports</h3>
Files older than the configured numnber of days will be automatically deleted from the Export directory.
Controls the volume of data left on the filesystem by the schedule.
</p>
<h3>Importing Signatures</h3>
Identifies Signatures file in the Import Directory for import.
<h4>Rules of import</h4><li>
<li>If data is newer in time but for the same day as Current information, then the current information will be overwritten</li>
<li>If data is older in time but for the same day as Current information, the import data will be discarded</li>
<li>If data is for a newer day than the Current information. The current information will be moved to a historic view and new data imported as Current.</li>
<li>If data is older than current and where there is no historic record for the day, the data will be imported to the historic view and current data is unchanged</li>
<li>If data is older than current but where there is already historic data and the import data is newer in time, the historic data will be overwritten</li>
<li>If data is older than current but where there is already historic data and the import data is older in time, the import data is discarded and the historic data is unchanged</li>
</ul>]]></Description>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	set stdout=$IO
	set tSC=$$$OK
	// Initialise process
	Kill ^||Data,^||DataSrc
	
	// Check that this task is not already running
	Lock +^ompare.Schedule:2
	Quit:'$T $$$ERROR(5001,"Task already running") // Task already running so exit
	
	do ..DebugLine("******************************************")
	do ..DebugLine("  Schedule Starting "_$ZDT($H,3))
	do ..DebugLine("******************************************")
	
	// Delete all previous reporting data
	if ..DiscardProfileData {
		do ..DebugLine("Initialise... Remove previous Profile Data requested")
		Do ..PurgeProfileData()	
	}
	
	// Convenience syntax. Reformat Namespace List
	// Expand "*" to all namespaces
	// Expand "-[Namespace]" to strip the namespace from the list
	// Tests each namespace exists
	do ..DebugLine("Configured Namespace List = "_..Namespaces)
	set nslen=$L(..Namespaces,",")
	kill nslist
	for i=1:1:nslen {
		set ns=$ZSTRIP($Piece(..Namespaces,",",i),"<>W")
		continue:ns=""
		set nsprefix=$Piece(ns,"*")
		if $E(ns,*)="*",$E(ns,1)'="-" {
			if ns="*" {
				do ..DebugLine("Expanding namespace list for ALL (""*"")")
			} else {
				do ..DebugLine("Expanding namespace list starting with prefix ("""_nsprefix_""")")
			}
							
			// ADD ALL namespaces to the list
			set nsrs=##class(%ResultSet).%New("%SYS.Namespace:List")
			if nsrs.Execute(0,1)  // Exclude remote and do not connect
			{
				for {
					quit:'nsrs.Next()
					set ns=nsrs.Data("Nsp")
					continue:ns=""
					if nsprefix="" {
						set nslist(ns)=""
						continue
					}
					if nsprefix=$Extract(ns,1,$Length(nsprefix)) {
						set nslist(ns)=""
						continue
					}
				}
			}
			set nsrs=""
			continue	
		}
		// Minus prefix = Remove Namespace from List
		if $E(ns,1)="-" {
			// Removed the leading minus sign
			set ns=$E(ns,2,*)
			// Prefix has no leading minus sign or trailing wild card
			set nsprefix=$Piece(ns,"*")
			continue:ns=""
			// Exact Match for Namespace
			if $E(ns,*)'="*" {
				if '##class(%SYS.Namespace).Exists(ns) {
					do ..DebugLine("Ignoring Exclude namespace rule ""-"_ns_""". Namespace does not exist.")
					continue
				} else {
					do ..DebugLine("Excluding namespace """_ns_"""")
					kill nslist(ns)  // remove a previously added entry
					continue		
				}
			} elseif $E(ns,*)="*",nsprefix'="" {
				// Wild Card processing
				do ..DebugLine("Wild Card Proceesing for rule -"_ns)
				set nsrs=##class(%ResultSet).%New("%SYS.Namespace:List")
				if nsrs.Execute(0,1)  // Exclude remote and do not connect
				{
					for {
						quit:'nsrs.Next()
						set nsq=nsrs.Data("Nsp")
						continue:nsq=""

						if nsprefix=$Extract(nsq,1,$Length(nsprefix)) {
							// Delete previous entry
							do ..DebugLine("Excluding namespace """_nsq_"""")
							kill nslist(nsq)
							continue
						}
					}
				}
				set nsrs=""
			}
			
			continue	
		}
		// Exact Match for namespace
		if '##class(%SYS.Namespace).Exists(ns) {
			do ..DebugLine("Ignoring Include namespace rule "_ns_""". Namespace does not exist.")
			continue	
		}
		do ..DebugLine("Including namespace """_ns_"""")
		set nslist(ns)=""
	}
	// Now reassemble namespace list for normal processing
	set (ns,nslist)=""
	for {
		set ns=$Order(nslist(ns))
		quit:ns=""
		set nslist=nslist_ns_","
	}
	do ..DebugLine("Expanded / Resolved Namespace List = "_nslist)
		
	if ..RunSourceHandlers {
	
		if $O(..PerNamespaceSourceHandlers(""))="",$O(..SystemSourceHandlers(""))="" {
			// Discover deployed Source handlers
			set rs=##class(%ResultSet).%New()
			set rs.ClassName="%Dictionary.ClassDefinition"
			set rs.QueryName="SubclassOf"
			if rs.Execute("ompare.SourceHandler.Base") {
				while rs.Next() {
					set sourceHandler=rs.Data("Name")
					do ..DebugLine("Query SubclassOf SourceHandler.Base: "_sourceHandler)
					continue:sourceHandler=""
					
					// Check whether this is a per-namespace
					//InvokePerNamespace
					set perNamespace=1  // default to true if not overriden in sub-class
					set perNamespace=$PARAMETER(sourceHandler,"InvokePerNamespace")
					if perNamespace=1 {
						do ..DebugLine("Register per Namespace SourceHandler "_sourceHandler)
						set perNamespaceSourceHandlers(sourceHandler)=""
					} else {
						do ..DebugLine("Register per System SourceHandler "_sourceHandler)
						set systemSourceHandlers(sourceHandler)=""
					}
					set parameter=""
				}	
			}
			do rs.Close()
			set rs=""
		} else {
			set sourceHandler=""
			for {
				set sourceHandler=$O(..PerNamespaceSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				if ##class(%Dictionary.CompiledClass).%ExistsId(sourceHandler) {
					set perNamespaceSourceHandlers(sourceHandler)=""
				} else {
					do ..DebugLine("Skipping unknown PerNamespaceSourceHandlers """_sourceHandler_"""")
				}
			}
			set sourceHandler=""
			for {
				set sourceHandler=$O(..SystemSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				if ##class(%Dictionary.CompiledClass).%ExistsId(sourceHandler) {
					set systemSourceHandlers(sourceHandler)=""
				} else {
					do ..DebugLine("Skipping unknown SystemSourceHandlers """_sourceHandler_"""")
				}	
			}
		}	
		if ..RetainSigSrcHistoricVersions>0 {
			// Also initialises current Data
			Do ..SaveHistoricData(..Environment)
		} else {
			// Initialise Current Data
			// Delete ALL current Data in expectation of new
			// We don't want a combination of OLD + NEW
			Kill ^ompare("Data",..Environment)
		
			// Initalise DateTime for new Data
			// Format
			//   Date
			//   Time
			//   Server
			//   Instance
			set ^ompare("Data",..Environment)=$TR($P($H,"."),",","^")_"^"_$TR($SYSTEM,":","^")
				
		}
		if ..OverwriteSourceOnReLoad {
			do ..DebugLine("Skipping BuildExistingDataSrcList - OverwriteSourceOnReLoad flag is set")
		} else {
			Do ..BuildExistingDataSrcList()
		}
	
		set ns=""
		for {
			set ns=$Order(nslist(ns))
			quit:ns=""
			
			// For each Sub-classes of ompare.SourceHandler.Base"
			set sourceHandler=""
			for {
				set sourceHandler=$Order(perNamespaceSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				try {
					Kill ^||Data
					// Build up new ^||Data for signatures and update ^||DataSrc
					do ..DebugLine("Running SourceHandler "_sourceHandler_" in namespace "_ns_" IncludeSourceCode="_..IncludeSourceCode)
					Do $CLASSMETHOD(sourceHandler,"IndexNamespace",ns,..EnableLogging,..IncludeSourceCode)
					
					Merge ^ompare("Data",..Environment,ns)=^||Data
							
				} catch errobj {
					// Error in BACKUP
					// Catches intentional <ENDOFFILE>
    				if ..Debug {
	    				u stdout WRITE "In Catch block standard export of source code",!
						u stdout WRITE "  Error Name:",errobj.Name,!
    					u stdout WRITE "  Error code: ",errobj.Code,!
    					u stdout WRITE "  Error location: ",errobj.Location,!
    					u stdout WRITE "  Error data:",errobj.Data,!
	    			}	
				}
				Kill ^||Data
			}
		}
	
		// Now run system wide Source Handlers
		set sourceHandler=""
		for {
			set sourceHandler=$Order(systemSourceHandlers(sourceHandler))
			quit:sourceHandler=""
			try {
				Kill ^||Data
				do ..DebugLine("Running System Wide Source Handlers SourceHandler "_sourceHandler_" for system context ")
				Do $CLASSMETHOD(sourceHandler,"IndexNamespace",ns,..EnableLogging,..IncludeSourceCode,..SrcVersionTokenStart,..SrcVersionTokenEnd)
			
				Merge ^ompare("Data",..Environment,ns)=^||Data

			} catch errobj {
				// Error in BACKUP
				// Catches intentional <ENDOFFILE>
    			do ..DebugLine("In Catch block System Wide Source Handlers")
				do ..DebugLine("  Error Name:"_errobj.Name)
    			do ..DebugLine("  Error code: "_errobj.Code)
    			do ..DebugLine("  Error location: "_errobj.Location)
    			do ..DebugLine("  Error data:"_errobj.Data)
	    		
			}
			Kill ^||Data
		}
	
		Do ..ApplyChangesDataSrc(..OverwriteSourceOnReLoad)
		Kill ^||DataSrc
	
		// Truncate Obsolete Historic Signatures
		// Truncate Obsolete Src entries no longer needed because they are no longer referenced by a signature on this system
		Do ..PurgeSigSource(..RetainSigSrcHistoricVersions,..Debug)
		// End RunSourceHandlers - Processing
	}
	// Generate Export Files if necessary
	do {
		Quit:'..ExportToFile
		if '##class(%File).DirectoryExists(..ExportDirectory)
		{
			set tSC=$$$ERROR(5001,"ExportDirectory "_..ExportDirectory_" not found")
			Quit
		}
		// CCYYMMDDHHSS
		set dateh=$TR($ZDT($H,8,2,4,0)," :")
		set datafile=..ExportDirectory_$S($E(..ExportDirectory,*)'?1(1"/",1"\"):$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"),1:"")_..#ExportSignaturePrefix_..Environment_dateh_$S(..ExportCompression:".gz",1:".tx")
		do ..DebugLine("Exporting Signatures to filepath "_datafile)
		set opened=0
		if ..ExportCompression {
			Open datafile:("NWS":/GZIP=1):2
			set opened=$T
		} else {
			Open datafile:("NWS"):2
			set opened=$T
		}
		if opened {
			use datafile Do ..ExportDataToDevice(..Environment)
		} else {
			do ..DebugLine("Unable to create file "_datafile)	
		}
		close datafile
		
		set datafile=..ExportDirectory_$S($E(..ExportDirectory,*)'?1(1"/",1"\"):$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"),1:"")_..#ExportSourcePrefix_..Environment_dateh_$S(..ExportCompression:".gz",1:".tx")
		do ..DebugLine("Exporting Source to filepath "_datafile)
		set opened=0
		if ..ExportCompression {
			Open datafile:("NWS":/GZIP=1):2
			set opened=$T
		} else {
			Open datafile:("NWS"):2
			set opened=$T
		}
		if opened {
			use datafile Do ..ExportDataSrcToDevice()
		} else {
			do ..DebugLine("Unable to create file "_datafile)		
		}
		close datafile
		
	} while (0)
	// Purge old export files based on schedule policy
	if ..RetainExportDays?1.2N,($L(..ExportDirectory)>2),##class(%File).DirectoryExists(..ExportDirectory) {
		Do ..PurgeOldFiles(..ExportDirectory,..RetainExportDays,..Debug)
	}
	
	do {
		Quit:'..ImportFromFile
		if $L(..ImportDirectory)<2 {
			do ..DebugLine("ImportDirectory parameter is Empty")
			Quit
		}
		if '##class(%File).DirectoryExists(..ImportDirectory) {
			do ..DebugLine("Import Directory "_..ImportDirectory_" not accessible")
			Quit
		}
		Do ..ProcessImportDirectory()
	} while (0)
	
	// Do we require a standard export of source code from each named namespace
	if ..BackupSourceCode {
		set ns=""
		for {
			set ns=$Order(nslist(ns))
			quit:ns=""	
			
			try {
				// Build up new ^||Data for signatures and update ^||DataSrc
				do ..DebugLine("Backing up source code in namespace "_ns)
				
				set tSC=..GenerateBackupSourceCode(ns,..ExportDirectory,..Environment)
				if $$$ISERR(tSC) {
					do ..DebugLine("Error generating Backup for Source code in namespace "_ns)
					do ..DebugLine($SYSTEM.Status.GetOneErrorText(tSC))
				}
							
			} catch errobj {
				// Error in BACKUP
				// Catches intentional <ENDOFFILE>
    			do ..DebugLine("In Catch block Backup Source Code")
				do ..DebugLine("  Error Name:"_errobj.Name)
    			do ..DebugLine("  Error code: "_errobj.Code)
    			do ..DebugLine("  Error location: "_errobj.Location)
    			do ..DebugLine("  Error data:"_errobj.Data)
	    			
			}
		}
	}
	
	// Delete any reporting data generated by this schedule
	if ..DiscardProfileData {
		do ..DebugLine("Clean Up... Remove Profile Data requested")
		Do ..PurgeProfileData()	
	}
	
	do ..DebugLine("*******************************************")
	do ..DebugLine("  Schedule Completed "_$ZDT($H,3))
	do ..DebugLine("*******************************************")
	
	// The unlocking is useful when a schedule is run
	// programatically from a command line or process that
	// does not exit after completion.
	Lock -^ompare.Schedule
	
	Quit $$$OK
]]></Implementation>
</Method>

<Method name="SaveHistoricData">
<Description><![CDATA[
Back-up current data if older than new generated / imported data
Truncates current or historic data to be replaced
If a newer version of data exists for the current day - this will simply be overwritten with latest data
Return Values<ul>
<li>0 = Abandon the Import. Data in file is obsolete</li>
<li>1 = Continue with Export / Import. Write to Current Data</li>
<li>2 = Continue with Import. Write to Historic Data</li>
</ul>]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>environment="",dateOfData=+$H,timeOfData={$P($H,",",2)},serverAndInstance={$TR($SYSTEM,":","^")}</FormalSpec>
<Implementation><![CDATA[
	quit:environment="" 0
	quit:dateOfData="" 0
	// Defaults: dateOfData, timeOfData and serverAndInstance
	
	set previousDate=+$P($G(^ompare("Data",environment)),"^")
	set previousTime=+$P($G(^ompare("Data",environment)),"^",2)
	set historicTime=+$P($G(^ompare("History",dateOfData,environment)),"^",2)
	set previousServerAndInstance=$P($G(^ompare("Data",environment)),"^",3,99)
	
	if previousDate<dateOfData {
		//W !,"SaveHistoricData = previousDate<dateOfData"
		// Trucate any previous historic data for this date
		kill ^ompare("History",previousDate,environment)
		
		// Move to historic if current data exists
		// Copies both date and time to historic node
		merge ^ompare("History",previousDate,environment)=^ompare("Data",environment)
		
		// Delete current Data in expectation of new
		Kill ^ompare("Data",environment)
		
		// Initalise DateTime for new Data
		set ^ompare("Data",environment)=dateOfData_"^"_timeOfData_"^"_serverAndInstance
		
		// Proceed with Export / Import
		Quit 1
		
	} elseif previousDate=dateOfData {
		//W !,"SaveHistoricData = previousDate=dateOfData"
		if previousTime<timeOfData {
			// Overwrite current Data
			// Delete current data in expectation of new
			Kill ^ompare("Data",environment)
			
			// Initalise DateTime for new Data
			set ^ompare("Data",environment)=dateOfData_"^"_timeOfData_"^"_serverAndInstance
			
			Quit 1	
		} else {
			// Abandon Import - Data saved in database is newer than import file
			Quit 0
		}
	} elseif previousDate>dateOfData {
		//W !,"SaveHistoricData = previousDate>dateOfData"
		// Write historic records
		if historicTime<timeOfData {
			// Overwrite historic Data
			Kill ^ompare("History",dateOfData,environment)
			
			// Initalise DateTime for historic Data
			set ^ompare("History",dateOfData,environment)=dateOfData_"^"_timeOfData_"^"_previousServerAndInstance
			
			Quit 2
			
		} else {
			//W !,"H4"
			// Abandon Import 
			Quit 0	
		}
	}
	
	Quit 0
]]></Implementation>
</Method>

<Method name="BuildExistingDataSrcList">
<Description>
Build a process private list of existing code signatures and their last know active date</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	Kill ^||DataSrc
	set sig=""
	for {
		set sig=$Order(^ompare("DataSrc",sig))
		quit:sig=""
		// By default if any previously existing signatures do not exist apply todays date
		set date=$G(^ompare("DataSrc",sig),+$H)
		set ^||DataSrc(sig)=date
	}
]]></Implementation>
</Method>

<Method name="ApplyChangesDataSrc">
<Description>
Updates the current date held against source code signatures
Saves additional new source code</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>overwriteSourceOnReLoad=0</FormalSpec>
<Implementation><![CDATA[
	// Using iterate instead of block merge to reduce Journal impact
	set sig=""
	for {
		set sig=$O(^||DataSrc(sig))
		quit:sig=""
		// remove / truncate if required
		kill:overwriteSourceOnReLoad ^ompare("DataSrc",sig)
		if $Data(^ompare("DataSrc",sig))=0 {
			merge ^ompare("DataSrc",sig)=^||DataSrc(sig)  // New data
		} elseif ($G(^ompare("DataSrc",sig))<^||DataSrc(sig)){
			set ^ompare("DataSrc",sig)=^||DataSrc(sig)  // Update still in use date
		} else {
			// No change in date used.
			// Obsolete information from current date but still maybe relavent for historic data
		}
	}
]]></Implementation>
</Method>

<Method name="ExportDataToDevice">
<Description>
Output Source Signatures to the open device (gzip file or Terminal)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>environment=""</FormalSpec>
<Implementation><![CDATA[
	quit:environment=""
	
	W "ENV|",$TR(environment,"|"),"|",$TR($G(^ompare("Data",environment)),"^","|"),!
	set namespace=""
	for {
		set data=""
		set namespace=$Order(^ompare("Data",environment,namespace),+1,data)
		quit:namespace=""

		W "NSP|",$TR(namespace,"|"),"|",$TR(data,"^","|"),!  // Append as pipe delimted data from global
		
		set type=""
		for {
			set type=$Order(^ompare("Data",environment,namespace,type))
			quit:type=""
			
			set typename=""
			for {
				set typename=$Order(^ompare("Data",environment,namespace,type,typename),+1,data)
				quit:typename=""
				
				W "TYP|",$TR(type,"|"),"|",$TR(typename,"|"),"|",data,!
				
				set subtype=""
				for {
					set subtype=$Order(^ompare("Data",environment,namespace,type,typename,subtype))
					quit:subtype=""
				
					set subtypename=""
					for {
						set subtypename=$Order(^ompare("Data",environment,namespace,type,typename,subtype,subtypename),+1,data)
						quit:subtypename=""
					
						W "SUB|",$TR(subtype,"|"),"|",$TR(subtypename,"|"),"|",data,!
					}
				}
			}
			
		}
	}
	W "END|||",!
]]></Implementation>
</Method>

<Method name="ExportDataSrcToDevice">
<Description>
Output Source snapshot to the open device (gzip file or Terminal)</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	set sig=""
	for {
		set data=""
		set sig=$O(^ompare("DataSrc",sig),+1,data)
		quit:sig=""
		W "S|",sig,"|",data,!
		
		set line=""
		for {
			set data=""
			set line=$O(^ompare("DataSrc",sig,line),+1,data)
			quit:line=""
			W "L|",data,!
		}
	}
	W "END|||",!
]]></Implementation>
</Method>

<Method name="PurgeOldFiles">
<Description><![CDATA[
Removes old export files from the filesystem
Expects files in format
<example>
ExportSignaturePrefix + Environment + CCYYMMDDHHMM + ".gz"
ExportSourcePrefix + Environment + CCYYMMDDHHMM + ".gz"
</example>
For example
<example>
SrcUtilDataSigUAT201601011023.gz
SrcUtilDataSrcUAT201601011245.gz
</example>]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>directory,retain=5,debug=0</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if debug {
		W !,"PurgeOldFiles called."
		W !,"  >> Directory=",directory
		W !,"  >> Retain Days=",retain
	}
	
	set tSC=$$$OK
	set deleteBeforeHorolog=$H-retain
	for prefix=..#ExportSignaturePrefix,..#ExportSourcePrefix {
		// File ResultSet
		set rs=##class(%ResultSet).%New()
		set rs.ClassName="%File"
		set rs.QueryName="FileSet"
		set tSC=rs.Execute(directory,prefix_"*.gz;"_prefix_"*.tx",0)
		
		// Expect prefix + Environment + CCYYMMDDHHMM
		set tSC=$$$OK
		for {
			Quit:'rs.Next(.tSC)
			Quit:$$$ISERR(tSC)
			
			set path=rs.Data("Name")
			set filename=##class(%File).GetFilename(path)

			// Extracts the date part of the filename for comparison with todays date
			// Don't trust filesystem timestamp
			set ccyymmdd=$E(filename,*-14,*-7)
			if ccyymmdd'?8N {
				w:debug !,"Skipping file ",filename," invalid format"
				continue
			}
			set hd=$ZDH(ccyymmdd,8,,4,,,,,"")
			if hd<1 {
				w:debug !,"Skipping file ",filename," invalid format"
				continue
			}
			// Ignore files that should be retained
			if hd>=deleteBeforeHorolog {
				W:debug !,"Retaining file ",filename,". Within Retain ",retain," days."	
				continue
			}
			W:debug !,"Deleting file ",filename
			do ##class(%File).Delete(path)
		}
	}
	quit tSC
]]></Implementation>
</Method>

<Method name="Test1">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	set o=##class(ompare.Schedule).%New()
	set o.Environment="VAL"
	set o.Namespaces="INTEG-TCL"
	set o.ExportToFile=1
	set o.ExportDirectory="/trak/lab/traktemp"
	set o.RetainExportDays=5
	set o.EnableLogging=0
	set o.IncludeSourceCode=1
	set o.Debug=0
	set tSC=o.OnTask()
	do $SYSTEM.Status.DisplayError(tSC)
]]></Implementation>
</Method>

<Method name="Test2">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	
	set directory="/trak/lab/traktemp/"
	set extension=".gz"
	
	// Normal format test Signature
	set datetime=$TR($ZDT($H,8,2,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"1_SIG_PASS"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	//set dateh=$TR($ZDT($H,8,2,4,0)," :")
	// Normal format test Source code
	set path=directory_..#ExportSourcePrefix_"2SRC_PASS"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// Abnormal prefix test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_"ABC"_..#ExportSourcePrefix_"3PrefixFail"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// File format date format test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"4DateFormatFail"_"datetime"_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// File format date invalid test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"5DateInvalidFail"_"9"_$E(datetime,2,12)_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	//Do ..ProcessImportDirectory(directory,1,1)
	
	set o=##class(ompare.Schedule).%New()
	set o.Environment="TEST"
	set o.Namespaces="INTEG-TCL"
	set o.RunSourceHandlers=0
	set o.ExportToFile=0
	set o.ExportDirectory=""
	set o.ImportDirectory="/trak/lab/traktemp"
	set o.ImportFromFile=1
	set o.ReImportUpdatedFiles=1
	set o.DeleteImportedFiles=1
	set o.RetainExportDays=5
	set o.EnableLogging=0
	set o.IncludeSourceCode=0
	set o.Debug=1
	
	do o.ProcessImportDirectory()
	
	//set tSC=o.OnTask()
	//do $SYSTEM.Status.DisplayError(tSC)
]]></Implementation>
</Method>

<Method name="ProcessImportDirectory">
<Description>
Main method to start importing Signatures and Code Snapshot from Import Directory</Description>
<Implementation><![CDATA[
	Quit:..ImportFromFile=0
	if ..ImportFromFile=0 {
		W:..Debug !,"ImportFromFile disabled. End Process Import Directory."	
	}
	
	if ..ImportDirectory="" {
		W:..Debug !,"Import Directory is empty. End ProcessImportDirectory."
		quit
	}
	set ..ImportDirectory=..WithTrailingPathSeperator(..ImportDirectory)
	W:..Debug !,"Import Directory=",..ImportDirectory
	
	set tSC=$$$OK
	/// Only gzip files with the given prefix will be processed AND optionally deleted.
	for prefix=..#ExportSignaturePrefix,..#ExportSourcePrefix {
		// File ResultSet
		set rs=##class(%ResultSet).%New()
		set rs.ClassName="%File"
		set rs.QueryName="FileSet"
		set tSC=rs.Execute(..ImportDirectory,prefix_"*.gz;"_prefix_"*.tx",0)
		if $$$ISERR(tSC) {
			W:..Debug !,$SYSTEM.Status.GetOneErrorText(tSC)	
			continue
		}
		
		// Expect prefix + Environment + CCYYMMDDHHMM
		set tSC=$$$OK
		for {
			Quit:'rs.Next(.tSC)
			if $$$ISERR(tSC) {
				W:..Debug !,$SYSTEM.Status.GetOneErrorText(tSC)	
				continue
			}

			set path=rs.Data("Name")
		
			W:..Debug !,"Verify file ",path
			
			set filename=##class(%File).GetFilename(path)

			// Extracts the date part of the filename for comparison with todays date
			// Don't trust filesystem timestamp
			set ccyymmddmm=$E(filename,*-14,*-7)_" "_$E(filename,*-6,*-5)_":"_$E(filename,*-4,*-3)
			if ccyymmddmm'?8N1" "2N1":"2N {
				w:..Debug !,"Skipping file ",filename," invalid date format"
				if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				}
				continue
			}
			set hd=$ZDTH(ccyymmddmm,8,2,4,,,,,,"")
			if ((+hd<1)||(+hd>94599)) {
				w:..Debug !,"Skipping file ",filename," invalid date value"
				if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				}
				continue
			}
			// Ignore files that have already been imported
			set dateh=##class(%File).GetFileDateModified(path,1)
			set dateh=($P(dateh,",")*86400)+$P(dateh,",",2)  // Convert to seconds
			
			set dateTimeChanged=$Get(^ompare("ImportedModified",filename))
			// Re-importing modified files enabled
			if ..ReImportUpdatedFiles {
				if dateTimeChanged'="" {
					if dateh=dateTimeChanged {
						W:..Debug !,"Skipping previous processed file ",path," - Modified date unchanged"
						if ..DeleteImportedFiles {
							W:..Debug !,"Deleting file ",path
							do ##class(%File).Delete(path)	  
						}
				  		continue
					} elseif dateh<dateTimeChanged {
						W:..Debug !,"Skipping previous processed file ",path," - Modified date older"
						if ..DeleteImportedFiles {
							W:..Debug !,"Deleting file ",path
							do ##class(%File).Delete(path)	  
						}
				  		continue	
					}
				}
			} else {
				if $Data(^ompare("ImportedModified",filename))
				{
					W:..Debug !,"Skipping previously processed file ",path
					if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				  	}
					continue
				}	
			}
			
			//TODO Process File			
			if prefix=..#ExportSignaturePrefix {
				Do ..ImportDataFromDevice(path,,..Debug)
			} else {
				Do ..ImportDataSrcFromDevice(path,..Debug,..OverwriteSourceOnReLoad)	
			}
			
			set ^ompare("ImportedModified",filename)=dateh  // $H date converted to seconds
			
			if ..DeleteImportedFiles {
				W:..Debug !,"Deleting file ",path
				do ##class(%File).Delete(path)	  
			}
			
		}
	}
	quit tSC
]]></Implementation>
</Method>

<Method name="ImportDataFromDevice">
<Description>
Import Signature file from Import directory device (filename)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>device=$IO,alias="",logging=0</FormalSpec>
<Implementation><![CDATA[
	set tSC=$$$OK
	set stdout=$IO
	// If device is a directory parse the directory for individual files with 

	/*
	ENV|VAL|64125|39580|Server|Instance  // Trust the Date and Time in the environment header for data insertion
	  P2 = ENVIRONMENT ALIAS on schedule eg: "VAL"
	  P3 = $H Date
	  P4 = $H Time
	  P5 = Server Name at time of analysis ie: May be clustered / mirrored / shadowed
	  P6 = Cache Instance Name - May be multiple instances on one cache server (At time of analysis)
	  
	  see: ompare.SourceHandler.Namespace
	NSP|INTEG-TCL|64125|39580|
	  P2 = Namespace name
	  P3 = $H Date of analysis
	  P4 = $H Time of analysis
	  P5 = Source Control Class
	  P6 = CCR Is Locked
	  P7 = Perforce Disconnected
	  P8 = Current Ensemble Production Name
	  P9 = CCR Organisation
	  P10= CCR System
	  P11= CCR Environment
	  P12= Role eg: INSTR, LABDB, INTEG
	  P13= Tags eg: CHIRP, EMPI, CHEMOCARE
	  P14= Depreciate Comment eg: Use Health Board specific namespace instead
	  
	TYP|C|CLNNHSW.CSAD|9gXg6Mi4x45TuF/3WOAuoxPGefE=
	SUB|M|AccessionNum|8FDHInI+JxJBKoH+kPM3FYGfc+g=
	*/
	// Check if file exists
	if device'=0 {
		if '##class(%File).Exists(device) {
			if logging u stdout w !,"File ",device," not found"	
			Quit
		}
		
		set fileExtension=$E(device,*-2,*)
		set datetime=$E(device,*-14,*-3)
		set environment=$E(device,$L(..#ExportSignaturePrefix)+1,*-15)
		if logging {
			u stdout W !,"Processing signature file"
			u stdout W !,"  From environment ",environment
			u stdout W !,"  Generated ",$E(datetime,1,4),"-",$E(datetime,5,6),"-",$E(datetime,7,8)," ",$E(datetime,9,10),":",$E(datetime,11,12)
		}
	
		set opened=0
		if fileExtension=".gz" {
			Open device:("RS":/GZIP=1):2
			set opened=$T
		} elseif fileExtension=".tx" {
			Open device:("RS"):2
			set opened=$T
		}
		if 'opened {
			if logging u stdout w !,"Unable to OPEN file "_device
			Quit	
		} else {
			if logging u stdout w !,"OPENed file "_device
		}
	}

	try {
		//TSTART
		// saveType
		//    When "0" obsolete date
		//    When "1" current Data
		//    When "2" Historic data
		// dateOfData
		//    Horolog Date from import file for environment
		set (env,nsp,typ,saveType,dateOfData,timeOfData)=""
		set race=0
		set maxRace=1000
		set cline=0
		for {
			Use device Read data:10
			if '$T {
				set race=race+1
				if race>maxRace {
					if logging u stdout w !,"Throwing error Race Conditon"
					THROW ##class(%Exception.StatusException).CreateFromStatus($$$ERROR(5001,"Race Condition"))
				}
				u stdout w !,"Bad read after:",!,"  p1=",p1,!,"  p2=",p2,!,"  p3=",p3,!,"  p4=",p4,!
				continue
			} else {
				set race=0				
				set cline=cline+1
				if logging>2 u stdout  W !,"Line:",cline
			}
			set p1=$P(data,"|")
			set p2=$P(data,"|",2)
			set p3=$P(data,"|",3)
			set p4=$P(data,"|",4,999)
			continue:p1=""
			
			if (p1="ENV") {
				if alias="" {
					set env=p2  // Trust the environment source from the file
				} else {
					set env=alias  // Override the environment value in the schedule for Testing OR Subscriptions
				}
				set (nsp,typ,typNam)=""
				continue:env=""
				
				
				// Trust the Date and Time in the environment header for data insertion
				// If the time for an imported file is older than the time for existing data for a given date skip the import
				set dateOfData=+p3
				// Date Validation
				continue:dateOfData<0
				continue:dateOfData>+$H  // More than todays date
				set timeOfData=+p4
				// Time validation
				continue:timeOfData<0
				continue:timeOfData>86399 // More than seconds in a day
				
				// Backup historic data, trucate historic data where necessary
				if logging u stdout w !,"Calling SaveHistoricData env=",env,", dateOfData=",dateOfData,", timeOfData=",timeOfData
				set saveType=..SaveHistoricData(env,dateOfData,timeOfData,$TR($Piece(p4,"|",2,999),"|","^"))
				if logging u stdout w !,"  saveType=",saveType
				if saveType=0
				{
					// Data is obsolete so ignore file contents
					set env=""
					if logging u stdout w !,"Ignoring obsolete data for environment ",env," for date ",$ZDT(dateOfData_","_timeOfData)
					continue		
				}				
			} elseif (p1="NSP") {
				continue:env=""
				set nsp=p2
				continue:nsp=""
				set (typ,typNam)=""
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp)=p3_"^"_$TR(p4,"|","^")
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""")="""_p3_"""^"_$TR(p4,"|","^")
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam)=p3_"^"_$TR(p4,"|","^")
				}
			} elseif (p1="TYP") {
				continue:env=""
				continue:nsp=""
				set typ=p2
				continue:typ=""
				set typNam=p3
				continue:typNam=""
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp,typ,typNam)=p4  // Type Signature Current
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""","""_typ_""","""_typNam_""")="""_p4_""""
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam)=p4  // Type Signature Historic
				}
				
			} elseif (p1="SUB") {
				continue:env=""
				continue:nsp=""
				continue:typ=""
				continue:typNam=""
				continue:p2="" // SUB Subtype code
				continue:p3="" // Sub type name
				continue:p4="" // Signature
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp,typ,typNam,p2,p3)=p4  // SubType Signature Current
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""","""_typ_""","""_typNam_""","""_p2_""","""_p3_""")="""_p4_""""
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam,p2,p3)=p4  // SubType Signature Historic
				}
			} elseif (p1="END") {
				quit
			}
		}
		// Code path occurs with END file
		// Required to mitigate issue with large GZIP files not detecting end of file on read
		///TCOMMIT
	} catch errobj {
		// Catches intentional <ENDOFFILE>
    	if errobj.Name'="<ENDOFFILE>",logging {
	    	u stdout WRITE "In Catch block Import Signature Code",!
			u stdout WRITE "  Error Name:",errobj.Name,!
    		u stdout WRITE "  Error code: ",errobj.Code,!
    		u stdout WRITE "  Error location: ",errobj.Location,!
    		u stdout WRITE "  Error data:",errobj.Data,!
	    	///TROLLBACK	
    	} else {
	    	/// Expected to hit EOF error
	    	///TCOMMIT	
    	}
	}
	Close:device'=0 device
	u stdout Write !,"End Import Signature File"
	Quit tSC
]]></Implementation>
</Method>

<Method name="ImportDataSrcFromDevice">
<Description>
Import Source file from Import directory device (filename)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>device=$IO,logging=0,overwriteSourceOnReLoad=0</FormalSpec>
<Implementation><![CDATA[
	set tSC=$$$OK
	set stdout=$IO

	// Check if file exists
	if device'=0 {
		if '##class(%File).Exists(device) {
			if logging u stdout W !,"File ",device," not found"	
			Quit
		}
		
		set fileExtension=$E(device,*-2,*)
		set datetime=$E(device,*-14,*-3)
		set environment=$E(device,$L(..#ExportSourcePrefix)+1,*-15)
		if logging {
			u stdout W !,"Processing signature file"
			u stdout W !,"  From environment ",environment
			u stdout W !,"  Generated ",$E(datetime,1,4),"-",$E(datetime,5,6),"-",$E(datetime,7,8)," ",$E(datetime,9,10),":",$E(datetime,11,12)
		}
	
		set opened=0
		if fileExtension=".gz" {
			Open device:("RS":/GZIP=1):2
			set opened=$T
		} elseif fileExtension=".tx" {
			Open device:("RS"):2
			set opened=$T
		}
		if 'opened {
			if logging u stdout W !,"Unable to OPEN file "_device
			Quit	
		} else {
			if logging u stdout W !,"File open "_device	
		}
	}
	
	try {
		//TSTART
		if logging u stdout w !,"In Transaction. Log Level=",logging
		
		set lineNum=0
		set (sig,date,line)=""
		set race=0
		set maxRace=1000
		for {
			Use device Read data:10
			if '$T {
				set race=race+1
				if race>maxRace THROW ##class(%Exception.StatusException).CreateFromStatus($$$ERROR(5001,"Race Condition"))
				continue
			} else {
				set race=0				
			}
			set lineNum=lineNum+1
			if logging>2 u 0 w !,lineNum //,":",$E(data,1,20)
			if $TR(data,$C(0,1,2,3,4,5,6,7,8,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31),"")'=data {
				u 0 w !,"BadChars in LineNum",lineNum
				for ctxt=0:1:$L(data) {
					for ttxt=0,1,2,3,4,5,6,7,8,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31 {
						if $C(ttxt)=$E(data,ctxt) u 0 w !,"  Charcode:",ttxt," at character ",ctxt	
					}	
				}
				u 0 w !,"  Sample BadContent",!,$E(data,1,20)
			}
			set p1=$P(data,"|")
			//set p2=$P(data,"|",2)
			//set p3=$P(data,"|",3)
			continue:p1=""
			
			if (p1="S") {
				
				set sig=$P(data,"|",2)
				set date=$P(data,"|",3)
				set line=0
				continue:sig=""
				// Work around for importing new code without date
				set:date="" date=+$H
				//continue:date=""
				
				set oldDate=+$G(^ompare("DataSrc",sig))
				if 'overwriteSourceOnReLoad,(oldDate>0) {
					if date>oldDate {
						// Update the date - Signature still in use
						set ^ompare("DataSrc",sig)=date
						// No need to re-import data so clear "sig" varible to ensure associated Source lines are skipped
						set sig=""
						set date=""
						continue
					}
				} else {
					// If overwriting - remove / truncate the previous source data
					kill:overwriteSourceOnReLoad ^ompare("DataSrc",sig)
					// Save the data - not seen before
					set ^ompare("DataSrc",sig)=date
					continue	
				}
			} elseif (p1="L") {
				continue:sig=""  // Discard Known Data
				continue:date=""	// Discard Known Data
				
				set line=line+1
				// Save the Source code line
				set ^ompare("DataSrc",sig,line)=$E(data,3,*)
				
			} elseif (p1="END") {
				// Terminate the file
				quit
			}	
		}
		// Code path occurs with END file
		// Required to mitigate issue with large GZIP files not detecting end of file on read
	} catch errobj {
		// Catches intentional <ENDOFFILE>
    	if errobj.Name'="<ENDOFFILE>",logging {
	    	u stdout WRITE "In Catch block Import Source File",!
			u stdout WRITE "  Error Name:",errobj.Name,!
    		u stdout WRITE "  Error code: ",errobj.Code,!
    		u stdout WRITE "  Error location: ",errobj.Location,!
    		u stdout WRITE "  Error data:",errobj.Data	
    	} else {
	    	/// Expected to hit EOF error
    	}
	}
	Close:device'=0 device
	u stdout Write !,"End Import Source File"
	Quit tSC
]]></Implementation>
</Method>

<Method name="WithTrailingPathSeperator">
<Description>
Adds trailing directory path seperator to directory path if needed</Description>
<ClassMethod>1</ClassMethod>
<CodeMode>expression</CodeMode>
<FormalSpec>directory</FormalSpec>
<Implementation><![CDATA[$Select($Extract(directory,*)?1(1"/",1"\"):directory,1:directory_$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"))
]]></Implementation>
</Method>

<Method name="PurgeSigSource">
<Description>
Operates on Historic data
Leave Current Data intact</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>retainVersionCount=0,debug=0</FormalSpec>
<Implementation><![CDATA[
	Quit:retainVersionCount<0
	
	// Itterates over any history for an environment
	set dateOfData=""
	for {
		set dateOfData=$Order(^ompare("History",dateOfData),-1)
		quit:dateOfData=""
		
		set environment=""
		for {
			set environment=$Order(^ompare("History",dateOfData,environment))
			quit:environment=""
			
			continue:($Increment(retain(environment)))<=retainVersionCount
			
			W:debug !,"Purge Historic Data for Envrionment ",environment," for date ",$ZD(dateOfData)
			Kill ^ompare("History",dateOfData,environment)		
		}
	}
	
	// Truncate Src data that is orphaned
	Kill ^||DataSig
	
	// Itterate over each Current Signature leaf node
	set node="^ompare(""Data"")"
	for {
		set node=$Query(@node)
		quit:node=""  // end of history global
		quit:$E(node,1,30)'="^ompare(""Data"","
		continue:$L(@node)'=28  // Must be SHA1 Signature in Base64 encoding
		set ^||DataSig(@node)=""	
	}
	
	
	// Itterate over each Historic Signature leaf node
	// Note each node that is a signature
	set node="^ompare(""History"")"
	for {
		set node=$Query(@node)
		quit:node=""  // end of history global
		quit:$E(node,1,33)'="^ompare(""History"","
		continue:$L(@node)'=28  // Must be SHA1 Signature in Base64 encoding
		set ^||DataSig(@node)=""	
	}
	
	set sig=""
	for {
		set sig=$Order(^ompare("DataSrc",sig))
		quit:sig=""
		// Truncate unreportable obsolete Source
		 
		if $Data(^||DataSig(sig))=0 {
			W:debug !,"Purge Obsolete Source ",sig
			kill ^ompare("DataSrc",sig)
		}
	}
]]></Implementation>
</Method>

<Method name="GenerateBackupSourceCode">
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace=$NAMESPACE,exportDirectory="",environment=""</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	Quit:$L(exportDirectory)<3 $$$ERROR(5001,"ExportDirectory invalid")
	Quit:'##class(%File).DirectoryExists(exportDirectory) $$$ERROR(5001,"ExportDirectory does not exist")
	Quit:environment="" $$$ERROR(5001,"Logical environment parameter empty")
	
	set ret=$$$OK
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
	
	set currentIO=$IO
	set qspec="/mapped=0/diffexport=1/exportgenerated=0/system=0/percent=0"
	//----------------
	// Export ALL to get full export list
	set file=##class(%IO.NullStream).%New()
	s dev=exportDirectory_"PreExportList"_$ZSTRIP(environment,"*W")_".txt"
	o dev:"NWS":2
	quit:'$T $$$ERROR(5001,"Unable to open ExportList Directory")
	u dev s tSC=$SYSTEM.OBJ.ExportToStream(..#ExportItemTypes,.file,qspec,.errorlog)
	c dev
	
	s file=##class(%File).%New(dev)
	d file.Open("RS")
	if 'file.AtEnd {
		for {
			set line=file.Read(32000)
			Quit:file.AtEnd
			
			if line?1"Exporting class: "1.E {
				set name=$P(line," ",3)
				if '$$IsExcluded(name_".cls") set items(name_".cls")=""
			} elseif line?1"Exporting routine: "1.E {
				// Exporting routine: TRAK.inc
				// Exporting routine: CLNNHSW03.mac
				set name=$P(line," ",3)
				if '$$IsExcluded(name) set items(name)=""
			} elseif line?1"Exporting type : "1.E {
				// HL7
				// Exporting type : 2.5.1.HL7
				// ASTM	
				// Exporting type : E1394.AST
				// RUL
				//Exporting type : Interfaces.Rules.RouteMsgFromTCL.rul
				set name=$P(line," ",4)
				if '$$IsExcluded(name) set items(name)=""
			} else {
				// Ignore the line
				// Exporting CSP/CSR or file: 
			}
		}
	}
	do file.%Close()
	//----------------
	Quit:'$Data(items) $$$ERROR(5001,"Nothing included for backup export")
	
	// Backup Any Defined Ensemble Lookups
	// ie: In Ensemble 2010 these are not managed as Studio "LUT" files.
	set lookupKey=""
	for {
		set lookupKey=$Order(^Ens.lookupTable(lookupKey))
		quit:lookupKey=""
		set:'$$IsExcluded(lookupKey_".lut") items("Ens.lookupTable("""_lookupKey_""").GBL")=""
	}
	
	Set stream=##class(%File).%New(exportDirectory_"BU_"_environment_"_"_$NAMESPACE_"_"_$TR($ZDT($H,3)," -:")_".gz")
	set tSC=stream.Open("NWS:/GZIP=9",2)
	Quit:$$$ISERR(tSC)
	
	set ret=$SYSTEM.OBJ.ExportToStream(.items,.stream,qspec,.errorlog)
	if $$$ISOK(ret) {
		Do stream.Flush()
	}
	Do stream.Close()
	
	Quit ret
IsExcluded(name)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Explict match for exlcusion
	Quit:+$G(^Ens.LookupTable("ompare.Exclude",name_"."_extension)) 1
	// now recursively look to exclude by wildcard match.
	set found=0
	
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^Ens.LookupTable("ompare.Exclude",prefix_"."_extension))
		quit:found
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
]]></Implementation>
</Method>

<Method name="IsExcluded">
<ClassMethod>1</ClassMethod>
<FormalSpec>name=""</FormalSpec>
<Implementation><![CDATA[
	Quit:name="" 1
	Quit:+$G(^Ens.LookupTable("ompare.Exclude",name)) 1
	// now recursively look to match by wildcard.
	set found=0
	set extension=$P(name,".",$L(name,"."))
	set prefix=$e(name,1,*-($L(extension)+1))_"*"
	for {
		set found=+$G(^Ens.LookupTable("ompare.Exclude",prefix_"."_extension))
		quit:found
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
]]></Implementation>
</Method>

<Method name="PurgeProfileData">
<Description>
Caution - When run on a Reporting Server this would
Also clear Signature data collected from other systems</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	Kill ^ompare("DataSrc")
	Kill ^ompare("Data")
	Kill ^ompare("History")
]]></Implementation>
</Method>

<Method name="DebugLine">
<Description>
Convenience method to output debug information to the console
in programmer mode OR the Task Schedule Log file if set</Description>
<FormalSpec>message</FormalSpec>
<Implementation><![CDATA[
	quit:'..Debug
	set:..STDOUT="" ..STDOUT=$IO
	USE ..STDOUT WRITE message,!
]]></Implementation>
</Method>

<Method name="TODO">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[	W !,$I(item),":SQLTable source encoding characters review"
]]></Implementation>
</Method>
</Class>
</Export>
